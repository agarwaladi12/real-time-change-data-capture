# MySQL â†’ Debezium â†’ Kafka â†’ Airflow â†’ BigQuery CDC Pipeline

This project demonstrates a **Change Data Capture (CDC)** pipeline built **without Docker**.  
We capture MySQL database changes using **Debezium**, stream them into **Kafka**, consume and transform the data with **Apache Airflow**, and finally load the clean data into **Google BigQuery**.

<br>

## âœ¨ Tech Stack

- **MySQL** â€” Source database
- **Debezium** â€” Captures CDC events from MySQL
- **Apache Kafka** â€” Event streaming platform
- **Apache Airflow** â€” Orchestrator for CDC pipeline
- **Google BigQuery** â€” Data warehouse (final destination)

<br>
## ðŸ›   Project Structure
cdc-project/
â”œâ”€â”€ airflow/                 # Airflow config and DAGs
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ debezium_to_bigquery.py
â”œâ”€â”€ airflow_setup/            # Setup steps for Airflow
â”‚   â””â”€â”€ airflow_connections.md
â”œâ”€â”€ kafka/                    # Kafka + Debezium configs
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ create_topics.sh
â”‚   â”œâ”€â”€ register-mysql.json
â”‚   â”œâ”€â”€ LICENSE
â”‚   â”œâ”€â”€ NOTICE
|   â”œâ”€â”€ plugins
â”‚   â””â”€â”€ licenses/
â”œâ”€â”€ mysql_setup/              # MySQL initialization scripts
â”‚   â””â”€â”€ init.sql
â”œâ”€â”€ requirements.txt          # Python and Airflow dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

<br>

---

## ðŸš€ How to Set Up and Run

### 1. Install Requirements

```bash
python3 -m venv airflow-venv
source airflow-venv/bin/activate
pip install -r requirements.txt

### 2. Setup MySQL Database

mysql -u root -p < mysql_setup/init.sql

### 3. Start Kafka and Zookeeper

# Start Zookeeper
bin/zookeeper-server-start.sh config/zookeeper.properties

# Start Kafka Broker
bin/kafka-server-start.sh config/server.properties

# Start Kafka Connect Distributed Worker
bin/connect-distributed.sh config/connect-distributed.properties

### 4. Create Kafka Topic

cd kafka/
bash create_topics.sh

### 5. Register Debezium Connector for MySQL

curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" \
--data @register-mysql.json \
http://localhost:8083/connectors/

### 6. Setup and Start Airflow

cd airflow
airflow db init
airflow standalone
